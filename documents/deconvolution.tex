%% This document is part of the HerschelDustMap project.
%% All content is Copyright 2015 the authors.

\documentclass[12pt, preprint]{aastex}

\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\TheTractor}{\project{The~Tractor}}
\newcommand{\Herschel}{\project{Herschel}}
\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\PACS}{\project{\acronym{PACS}}}
\newcommand{\SPIRE}{\project{\acronym{SPIRE}}}

\newcommand{\unit}[1]{{\mathrm{#1}}}
\newcommand{\mum}{\unit{\mu m}}

\begin{document}

\title{Inferring dust properties from 6-band \Herschel\ imaging \\ 
       but at the resolution of the highest resolution band}
\author{MK, DL, DWH}

\begin{abstract}
In many astronomical projects, images or angular maps are built from
multi-wavelength imaging that is also multi-resolution:
Every wavelength is imaged at a different angular resolution.
One method for uniformizing the resolution is to convolve or blur the
images to a common (usually the lowest) resolution, discarding
information.
Of the alternative approaches, the best from an information-theory
perspective is to forward model the full stack of multi-band,
multi-resolution images, accounting for the unique, finite resolution
of each image.
To make the problem well-posed, the optimization or inference must be
regularized with prior information about what kinds of spectral energy
distributions (\acronym{SED}s) are possible, and about the smoothness of the map.
Here we perform this forward modeling on 6-band \PACS\ and
\SPIRE\ imaging of M31 to map the dust at the resolution of the
highest resolution band (\PACS~$70\,\mum$).
We regularize the optimization with a simple model of dust emissivity.
We demonstrate that we can produce high-resolution dust density and
temperature maps, and make predictions for (hypothetical future)
higher-resolution infrared imaging.
We demonstrate the validity of the maps with cross-validation-like
tests of their predictive power.
We discuss limitations and extensions of the method, especially as
regards the flexibility of the \acronym{SED} model.
\end{abstract}

\section{Introduction}

Hello World.

\section{Method}

The goal is to map the dust in \Herschel\ imaging of M31 at high
angular resolution.
We want our maps to be \emph{correct}, by which we mean we want them
to be the best maps we can make under a clear set of assumptions or
approximations.
This requires that we clearly state our assumptions.

The assumptions of the method developed in this work are the
following:
\begin{itemize}
\item We have properly calibrated, astrometrically aligned images of
  the sky.
\item We have good approximations to the point-spread functions (PSFs)
  in the images.  Actually, all we really assume is that we know the
  kernels that smooth the PSF in the best-PSF band to the PSFs of the
  other bands.
\item The noise in the images is independent from pixel to pixel and
  of known variance. DWH: DO WE ASSUME THIS?
\item At the highest resolution we consider, each pixel contains only
  a single dust component, with a well-defined temperature and
  emmissivity parameter, and it's spectral energy distribution (SED)
  is well described by a particular, rigid emmissivity law.
\item The map is smooth; that is, the density, temperature, and
  emmissivity parameter maps vary smoothly, with angular covariance
  scales we specify.
\end{itemize}
All of these assumptions have limitations and are approximations to a
greater or lesser degree.
We will return in the Discussion Section to the question of what would
be different about our results if we modified them.
That said, it might be worth pointing out here that the weakest
assumption is the single-dust-component assumption:
This assumption isn't really consistent at all, since a map that obeys
this assumption at one resolution (one pixel size) will not, in
general, obey it at any coarser resolution (larger pixel size).

DWH: data is model plus noise.

DWH: likelihood functon.

DWH: smoothness prior.

DWH: optimization of what now?

DWH: implementation details?

\section{Experiments}

Hello World.

\section{Discussion}

What did we do?

What can we learn and predict that wasn't possible before?

What is likely to happen if we relax our assumptions?

How would this generalize to situations where there is no SED model,
or we don't know what regularities exist?

\acknowledgements
Brent Groves, Karin Sandstrom, Tomas Henning, etc.
Grant numbers, etc.
\acronym{NASA ADS}, etc.

\end{document}
